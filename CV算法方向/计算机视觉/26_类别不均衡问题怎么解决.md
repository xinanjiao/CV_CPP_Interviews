# 类别不均衡问题怎么解决？

## 什么是数据不平衡？
在学术研究与教学中，很多算法都有一个基本假设，那就是数据分布是均匀的。当我们把这些算法直接应用于实际数据时，大多数情况下都无法取得理想的结果。因为实际数据往往分布得很不均匀，都会存在“长尾现象”，也就是所谓的“二八原理”。

以二分类问题为例，假设正类的样本数量远大于负类的样本数量，通常情况下把样本类别比例超过4:1（也有说3:1）的数据就可以称为不平衡数据。

不平衡程度相同（即正负样本比例类似）的两个问题，解决的难易程度也可能不同，因为问题难易程度还取决于数据量。可以把问题根据难度从小到大排个序：大数据+分布均衡<大数据+分布不均衡<小数据+数据均衡<小数据+数据不均衡。

## 解决方法

先上结论：分为三个方向的解决部分**：数据方面、模型方面、评估方面：**

==数据方面==：

- **扩充数据集**

- **过采样**

  将小众样本复制多份，但这样很容易造成过拟合，所以可以在生成的样本中加入轻微扰动

- **欠采样**

  欠采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本。丢弃大量数据，和过采样一样会存在过拟合的问题。解决方法如下：

  - **Easy Ensemble:**多次欠采样（放回），训练多个分类器，组合获取更好的效果
  - **BlanceCascade:**类似增量训练思想（Boosting），分类准确大众样本不妨会，对准确率小的大众样本欠采样训练
  - **NearMiss：**利用KNN选择具有代表性的大众样本，但计算量很大

- **数据合成**

  数据合成方法是利用已有样本生成更多样本，其实**也可以归类于过采样**方法

  - **SMOTE** (synthetic minority oversampling technique) ：思想概括起来就是在少数类样本之间进行插值来产生额外的样本。
  - **对于文本数据**可以采用同义词替换、词语位置打乱等。
  - **对于图像数据**可以采用数据增强方法。

- 基于异常的检测方式

==从模型算法的方面==：

- **尝试不同的分类算法**

  决策树往往在类别不均衡的数据上表现不错，它使用基于类变量的划分规则去创建分类树，因此可以将不同类别的样本分开

- **对小类错分进行加权惩罚**

  如penalized-SVM和penalized-LDA算法

- **从重构分类器的角度出发**

  是否可以将你的问题划分为多个更小的问题，这些小问题更容易解决。

  - 将大类划分为小类
  - 使用One Class分类器，然后联合这些分类器进行分类
  - 将二分类问题改为多分类问题

==从评估角度出发，通常的方法包括：==

- **选择合适的评估指标**

  对于极端的类别不平衡的评估问题，我们一般用的指标有（前面是全局评估，最后一个是点评估）：

  - 混淆矩阵
  - Precision和Recall
  - F1得分
  - Kappa（Cohen kappa）
  - ROC曲线和AUC
  - mean Average Precesion（mAP），指的是在不同召回下的最大精确度的平均值
  - Precision@Rank k。假设共有n个点，假设其中k个点是少数样本时的Precision。这个评估方法在推荐系统中也常常会用
    

- **选择合适的损失函数**（OHEM或者Focal Loss)

  - **OHEM（online hard example miniing**）算法的核心思想是根据输入样本的损失进行筛选，筛选出hard example，表示对分类和检测影响较大的样本，然后将筛选得到的这些样本应用在随机梯度下降中训练。
  - **Focal loss**主要是为了解决one-stage目标检测中正负样本比例严重失衡的问题。ssd按照ohem选出了loss较大的，但忽略了那些loss较小的easy的负样本，虽然这些easy负样本loss很小，但数量多，加起来的loss较大，对最终loss有一定贡献。

- **选择合适的阈值**

- **设置不同类别的权重**

## 参考

[如何解决类别不均衡](https://blog.csdn.net/vivian_ll/article/details/105201120)